{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Некрасова Татьяна Валерьевна\n",
    "\n",
    "Команда: Polosataya\n",
    "\n",
    "Соревнование: Digital Reputation Challenge \n",
    "\n",
    "10 сентября - 10 октября 2019 года\n",
    "\n",
    "Платформа: https://boosters.pro/championship/digital_reputation_challenge/data\n",
    "\n",
    "3 место"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import catboost\n",
    "from lightgbm import LGBMClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool,cv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, ShuffleSplit, KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основная идея\n",
    "Данные анонимные, предсказать надо человеческое поведение. При выборе моделей я вспомнила \"Мудрость толпы\" Фрэнсиса Гальтона. Число наблюдений можно считать небольшим. Число фич тоже (вся Х2 по сути одна фича). Поэтому для хорошего результата нужны несколько принципиально отличающихся моделей, которые будут замечать разные особенности в данных. \n",
    "\n",
    "Были выбраны:\n",
    "- LogisticRegression - хорошо отлавливает линейные зависимости между переменными.\n",
    "- catboost - строит симметричные неглубокие дереверья.\n",
    "- lightgbm - строит глубокие деревья."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение и обработка Х1 и Х2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно загружать, сразу указав индекс, но он может понадобить, чтобы смержить таблицы. Поэтому индекс установим уже для готового датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Если использовать не разреженную матрицу то мержить Х1 и Х2 по индексу\n",
    "#X_train = X1_train.merge(X2_train, on='id', how='inner')\n",
    "#X_train = X_train.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = pd.read_csv('train/X1.csv')\n",
    "X1_test = pd.read_csv('test/X1.csv')\n",
    "\n",
    "X2_train = pd.read_csv('train/X2.csv')\n",
    "X2_test = pd.read_csv('test/X2.csv')\n",
    "Y = pd.read_csv('train/Y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>3092.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  1    2    3      4      5       6     7      8     9  ...  16  17  18  \\\n",
       "0   3  1 -1.0 -1.0  107.0  255.0   537.0  10.0   41.0   0.0  ...   0   0   0   \n",
       "1   5  0  0.0  0.0   20.0    0.0   188.0   1.0   25.0   2.0  ...   0   0   0   \n",
       "2   6  1  0.0  0.0  158.0  155.0  3092.0   3.0  218.0  29.0  ...   0   0   0   \n",
       "3   8  1  0.0  0.0  102.0  343.0   341.0   0.0   24.0   2.0  ...   0   0   0   \n",
       "4  10  1  0.0  0.0    1.0    1.0    33.0   0.0   41.0   1.0  ...   0   0   0   \n",
       "\n",
       "   19  20  21  22  23  24  25  \n",
       "0   0   0   0   1   0   1   0  \n",
       "1   0   0   0   0   0   0   0  \n",
       "2   0   0   0   0   1   0   0  \n",
       "3   0   0   0   1   0   0   0  \n",
       "4   0   0   0   1   0   1   0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблицах Х1 и Х3 колонки нумеруются по порядку. Чтобы не путаться, переименуем колонки Х1, добавив префикс 'Х1_'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train.columns = ['X1_' + str(i) for i in range(0, 26)]\n",
    "X1_train.rename({'X1_0': 'id'}, axis=1, inplace=True)\n",
    "X1_test.columns = ['X1_' + str(i) for i in range(0, 26)]\n",
    "X1_test.rename({'X1_0': 'id'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#В этом ноутбуке 'id', как фича, т.к. некоторые признаки сильно коррелируют с id. \n",
    "X1_train = X1_train.set_index('id')\n",
    "X1_test = X1_test.set_index('id')\n",
    "\n",
    "X1_train['id'] = X1_train.index\n",
    "X1_test['id'] = X1_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ показал, что распределение некоторых количественных переменных в Х1 ассиметрично. Исправим это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_col = ['X1_4', 'X1_5', 'X1_6', 'X1_7', 'X1_9',]\n",
    "for c in skewed_col:\n",
    "    X1_train[c] = np.log(X1_train[c]+2)\n",
    "    X1_test[c] = np.log(X1_test[c]+2)\n",
    "#другое\n",
    "    skewed_col = ['X1_8']\n",
    "for c in skewed_col:\n",
    "    X1_train[c] = np.log(X1_train[c]+0.5)\n",
    "    X1_test[c] = np.log(X1_test[c]+0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу пометим категориальные переменные, чтобы использовать их в бустингах. В последних решениях все данные были собраны в разреженную матрицу и необходимость в выделении категориальных фич отпала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['X1_1', 'X1_2', 'X1_3', 'X1_10', 'X1_11', 'X1_12', 'X1_13', 'X1_15', 'X1_16', 'X1_17', 'X1_18', \n",
    "            'X1_20', 'X1_21', 'X1_22', 'X1_23', 'X1_24', 'X1_25']\n",
    "cat_feat = [X1_train.columns.get_loc(c) for c in cat_cols if c in X1_train]\n",
    "#cat_feat = [c for c in cat_cols if c in X1_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала долго работала с Х3, т.к. она уже в виде таблицы. Но по Х3 идет сильное переобучение, выделить полезный сигнал очень трудно. В телеграме упомянули, что Х3 строится по Х2. А Х2 представляет собой посещаемые пользователем сайты.\n",
    "\n",
    "Сразу вспомнилось решение InClass соревнования с Kaggle про идентификацию пользователей сайта. Поскольку то решение до сих пор держится в топе, использовать Tfidf вместо того, чтобы работать с Х2 как с матрицей, показалось хорошим выбором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>70340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>72868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>73471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>74998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      A\n",
       "0   3      5\n",
       "1   3  70340\n",
       "2   3  72868\n",
       "3   3  73471\n",
       "4   3  74998"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переводим числа в текстовую строку для каждого пользователя для дальнейшего анализа Tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5 70340 72868 73471 74998 76085 76344 77490 68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>52464 53049 55398 63794 63865 146853 124018 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>109524 108377 108057 107971 105711 107366 1069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>76104 108776 82494 106467 189148 172358 130830...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>128427 133569 132866 132460 131402 130676 1287...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    A\n",
       "id                                                   \n",
       "3   5 70340 72868 73471 74998 76085 76344 77490 68...\n",
       "5   52464 53049 55398 63794 63865 146853 124018 15...\n",
       "6   109524 108377 108057 107971 105711 107366 1069...\n",
       "8   76104 108776 82494 106467 189148 172358 130830...\n",
       "10  128427 133569 132866 132460 131402 130676 1287..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = X2_train.groupby('id').agg({'A':lambda x: ' '.join(map(str, x))})\n",
    "df_train.columns = ['A']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3516 159588 146272 139933 139877 135954 133247...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>81239 85770 81928 82168 83379 83461 83805 8682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>90856 43470 29426 16362 14919 13951 27987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>78992 80049 83151 83345 89434 89678 90936 9312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>93635 89074 88919 83782 86227 82642 93714 8749...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    A\n",
       "id                                                   \n",
       "0   3516 159588 146272 139933 139877 135954 133247...\n",
       "1   81239 85770 81928 82168 83379 83461 83805 8682...\n",
       "2           90856 43470 29426 16362 14919 13951 27987\n",
       "4   78992 80049 83151 83345 89434 89678 90936 9312...\n",
       "7   93635 89074 88919 83782 86227 82642 93714 8749..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = X2_test.groupby('id').agg({'A':lambda x: ' '.join(map(str, x))})\n",
    "df_test.columns = ['A']\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Включаем ngram(от 1, 9) (1,5 тоже хорошо работает) и ограничиваем фичи до 50000. Для разных 'y' эти числа разные, но такая подгонка только ухудшала результат, поэтому взяла максимум (выбранный для на у4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfn = TfidfVectorizer(ngram_range=(1, 9),max_features=50000, sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = tfidfn.fit_transform(df_train.A)\n",
    "X_test_sparse = tfidfn.transform(df_test.A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение необработанных и обработанных колонок из Х1 показало, что лучше использовать StandardScaler. Объединим обе таблицы в одну матрицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "tmp_train = scaler.fit_transform(X1_train)\n",
    "tmp_test = scaler.transform(X1_test)\n",
    "\n",
    "X_train = csr_matrix(hstack([tmp_train, X_train_sparse]))\n",
    "X_test = csr_matrix(hstack([tmp_test, X_test_sparse]))\n",
    "\n",
    "X_train_ = csr_matrix(hstack([X1_train, X_train_sparse]))\n",
    "X_test_ = csr_matrix(hstack([X1_test, X_test_sparse]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У меня был опыт участия в подобном сореновании (поведение людей, ROC AUC ~ 0.6). Сложная схема валидации создавала ложную уверенность, что все под контролем. Как результат - падение на 250 мест из топа. В телеграме дискутировали о том, что надо использовать еще более сложную схему валидации. Но, по моему мнению, это похоже на \"колосса на глинянных ногах\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для кроссвалидации был проверены все валидаторы из sklearn.model_selection. Для них рассчитывалось mean и std по одному набору данных и сравнивалось с лидербордом. У ShuffleSplit было самое низкое стандартное отклонение. Остальные немного завышали скор и он очень сильно варьировался по фолдам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки качества моделей использовались три модели (logit, lgbc, catc) с зафиксированными настройками. В cross_val_score менялась проверяемая модель и менялся 'у' из Y. Если значение cross_val_score было ниже 0,59 - модель считалась плохой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = ShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "\n",
    "#logit = make_pipeline(StandardScaler(), LogisticRegression(solver = 'lbfgs', random_state=42))\n",
    "logit = LogisticRegression(random_state=42, C= 0.1, solver= 'lbfgs', max_iter= 100, class_weight= 'balanced', \n",
    "                           penalty='l2')\n",
    "lgbc = LGBMClassifier(objective = 'binary',  metric = 'auc', random_state=42,  boosting_type= 'gbdt',  \n",
    "                      learning_rate= 0.01, max_depth= 2, num_leaves= 2, n_estimators= 1000, \n",
    "                      subsample= 0.9, subsample_freq= 1, colsample_bytree= 0.9,) #device = 'gpu',\n",
    "catc = CatBoostClassifier(loss_function = 'Logloss', eval_metric = 'AUC', random_state=42, logging_level='Silent',\n",
    "                          task_type='GPU', leaf_estimation_iterations=1, depth = 2, l2_leaf_reg= 1.0,\n",
    "                         learning_rate = 0.01, bagging_temperature = 0.95, iterations= 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59464 0.57009 0.017\n"
     ]
    }
   ],
   "source": [
    "#При валидации менялись значения y_train (Y['1'], Y['2'], Y['3'], Y['4'], Y['5'])\n",
    "y_train = Y['1']\n",
    "#При валидации менялась модель (logit, lgbc, catc)\n",
    "scores = cross_val_score(logit, X_train, y_train, cv=ss, scoring='roc_auc')\n",
    "print((scores).mean().round(5), (scores).min().round(5), (scores).std().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первоначально парамтеры моделей подбирались hyperopt, но в ходе экспериментирования они так много раз менялись, что от первоначального варианта не осталось ничего.\n",
    "\n",
    "Первоначально для каждого y выбирался собственный датасет, но как оказалось - это вело к переобучению под тренировочные данные. Поэтому все предсказания делались по общему датасету, но с индивидуальными параметрами моделей. \n",
    "\n",
    "Для логистической регрессии органичение размерности с TruncatedSVD давало положительный результат. Модели деревьев наоборот лучше работали с полным набором данных.\n",
    "\n",
    "Для всех моделей предсказание делалось по 5 фолдам. В предсказании логистической регресси использовалась валидационная выборка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Параметры логистической регрессии одинаковые для всех моделей. \n",
    "logit = LogisticRegression(random_state=42, C= 1.0, solver= 'lbfgs', max_iter= 100, penalty='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предсказание для у1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Fold  1 roc_auc : 0.610088\n",
      "fold n°2\n",
      "Fold  2 roc_auc : 0.636057\n",
      "fold n°3\n",
      "Fold  3 roc_auc : 0.575049\n",
      "fold n°4\n",
      "Fold  4 roc_auc : 0.636043\n",
      "fold n°5\n",
      "Fold  5 roc_auc : 0.610719\n",
      "Out of folds AUC = 0.6123495208753538\n"
     ]
    }
   ],
   "source": [
    "#logit\n",
    "y_train = Y['1']\n",
    "svd = TruncatedSVD(n_components=200, algorithm='randomized', random_state=42)\n",
    "svd.fit(X_train)\n",
    "X_svd_train = svd.transform(X_train)\n",
    "X_svd_test = svd.transform(X_test)\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=22)\n",
    "y_1 = np.zeros(X_svd_test.shape[0])\n",
    "oof = np.zeros(X_svd_train.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_svd_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    X_trn = X_svd_train[trn_idx]\n",
    "    y_trn = y_train[trn_idx]\n",
    "    X_val = X_svd_train[val_idx]\n",
    "    y_val = y_train[val_idx]\n",
    "\n",
    "    clf = logit.fit(X_trn, y_trn)\n",
    "    oof[val_idx] = clf.predict_proba(X_val)[:, 1]\n",
    "    print('Fold %2d roc_auc : %.6f' % (fold_ + 1, roc_auc_score(y_val, oof[val_idx]))) \n",
    "    \n",
    "    y_1 += clf.predict_proba(X_svd_test) [:, 1] / folds.n_splits\n",
    "    \n",
    "print(f\"Out of folds AUC = {roc_auc_score(y_train, oof)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[285]\ttraining's auc: 0.703371\tvalid_1's auc: 0.62727\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's auc: 0.653468\tvalid_1's auc: 0.587949\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's auc: 0.682482\tvalid_1's auc: 0.582392\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[293]\ttraining's auc: 0.700035\tvalid_1's auc: 0.640453\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's auc: 0.725319\tvalid_1's auc: 0.586836\n",
      "[1000]\ttraining's auc: 0.77259\tvalid_1's auc: 0.593071\n",
      "Early stopping, best iteration is:\n",
      "[903]\ttraining's auc: 0.764247\tvalid_1's auc: 0.593451\n"
     ]
    }
   ],
   "source": [
    "#lgb\n",
    "params = {'objective' : 'binary', 'metric' : 'auc', 'boosting_type' : 'gbdt', \n",
    "           'colsample_bytree' : 0.3,  'subsample_freq' : 1,  'subsample' : 0.6,\n",
    "          'learning_rate': 0.01,  'num_leaves': 3, \n",
    "         }\n",
    "y_train = Y['1']\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=42)\n",
    "a1 = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold_n, (trn_idx, val_idx) in enumerate(folds.split(X_train_, y_train)):\n",
    "    print('Fold', fold_n + 1)\n",
    "    X_trn, X_val = X_train[trn_idx], X_train[val_idx]\n",
    "    y_trn, y_val = y_train[trn_idx], y_train[val_idx]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_trn, label=y_trn)\n",
    "    valid_data = lgb.Dataset(X_val, label=y_val)\n",
    "        \n",
    "    clf = lgb.train(params, train_data, num_boost_round=10000, valid_sets = [train_data, valid_data], \n",
    "                    verbose_eval=500, early_stopping_rounds = 100) #categorical_feature = cat_features, \n",
    "    \n",
    "    a1 += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "0:\tlearn: 0.5033431\ttest: 0.4973183\tbest: 0.4973183 (0)\ttotal: 34.2ms\tremaining: 3m 25s\n",
      "bestTest = 0.5882296562\n",
      "bestIteration = 211\n",
      "Shrink model to first 212 iterations.\n",
      "fold n°2\n",
      "0:\tlearn: 0.5027976\ttest: 0.4968032\tbest: 0.4968032 (0)\ttotal: 27.1ms\tremaining: 2m 42s\n",
      "bestTest = 0.6009210944\n",
      "bestIteration = 69\n",
      "Shrink model to first 70 iterations.\n",
      "fold n°3\n",
      "0:\tlearn: 0.5039889\ttest: 0.5017366\tbest: 0.5017366 (0)\ttotal: 32.7ms\tremaining: 3m 15s\n",
      "bestTest = 0.6455945075\n",
      "bestIteration = 152\n",
      "Shrink model to first 153 iterations.\n",
      "fold n°4\n",
      "0:\tlearn: 0.5058059\ttest: 0.5052574\tbest: 0.5052574 (0)\ttotal: 32.2ms\tremaining: 3m 12s\n",
      "bestTest = 0.59613958\n",
      "bestIteration = 160\n",
      "Shrink model to first 161 iterations.\n",
      "fold n°5\n",
      "0:\tlearn: 0.5034834\ttest: 0.4985459\tbest: 0.4985459 (0)\ttotal: 24.9ms\tremaining: 2m 29s\n",
      "bestTest = 0.5894202888\n",
      "bestIteration = 71\n",
      "Shrink model to first 72 iterations.\n",
      "CPU times: user 1min 14s, sys: 17.6 s, total: 1min 31s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#catboost\n",
    "params = {'loss_function' : 'Logloss', 'eval_metric' : 'AUC', 'logging_level' : 'Silent', 'task_type' : 'GPU',\n",
    "          'leaf_estimation_iterations': 2, 'boosting_type':'Ordered',   \n",
    "          'iterations': 400,  'depth':2,  'learning_rate': 0.02, \n",
    "         }\n",
    "\n",
    "y_train = Y['1']\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=42)\n",
    "b1 = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    trn_data = Pool(X_train[trn_idx], label=y_train[trn_idx])#, cat_features=cat_feat\n",
    "    val_data = Pool(X_train[val_idx], label=y_train[val_idx])#, cat_features=cat_feat\n",
    "\n",
    "    clf = catboost.train(params=params, pool = trn_data, eval_set=val_data, num_boost_round=6000, \n",
    "                         early_stopping_rounds=100, verbose_eval=1000) \n",
    "\n",
    "    #Прогноз\n",
    "    b1 += clf.predict(X_test, prediction_type='Probability')[:, 1] / folds.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предсказание для у2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Fold  1 roc_auc : 0.631425\n",
      "fold n°2\n",
      "Fold  2 roc_auc : 0.625044\n",
      "fold n°3\n",
      "Fold  3 roc_auc : 0.620593\n",
      "fold n°4\n",
      "Fold  4 roc_auc : 0.632084\n",
      "fold n°5\n",
      "Fold  5 roc_auc : 0.620413\n",
      "Out of folds AUC = 0.6253983034777513\n"
     ]
    }
   ],
   "source": [
    "#logit\n",
    "y_train = Y['2']\n",
    "svd = TruncatedSVD(n_components=200, algorithm='randomized', random_state=42)\n",
    "svd.fit(X_train)\n",
    "X_svd_train = svd.transform(X_train)\n",
    "X_svd_test = svd.transform(X_test)\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=22)\n",
    "y_2 = np.zeros(X_svd_test.shape[0])\n",
    "oof = np.zeros(X_svd_train.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_svd_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    X_trn = X_svd_train[trn_idx]\n",
    "    y_trn = y_train[trn_idx]\n",
    "    X_val = X_svd_train[val_idx]\n",
    "    y_val = y_train[val_idx]\n",
    "\n",
    "    clf = logit.fit(X_trn, y_trn)\n",
    "    oof[val_idx] = clf.predict_proba(X_val)[:, 1]\n",
    "    print('Fold %2d roc_auc : %.6f' % (fold_ + 1, roc_auc_score(y_val, oof[val_idx]))) \n",
    "    \n",
    "    y_2 += clf.predict_proba(X_svd_test) [:, 1] / folds.n_splits\n",
    "    \n",
    "print(f\"Out of folds AUC = {roc_auc_score(y_train, oof)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[107]\ttraining's auc: 0.676414\tvalid_1's auc: 0.609281\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's auc: 0.655692\tvalid_1's auc: 0.629752\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.647806\tvalid_1's auc: 0.633824\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's auc: 0.651137\tvalid_1's auc: 0.602305\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[161]\ttraining's auc: 0.673461\tvalid_1's auc: 0.611579\n"
     ]
    }
   ],
   "source": [
    "#lgb\n",
    "params =  {'objective' : 'binary', 'metric' : 'auc', 'boosting_type' : 'gbdt', \n",
    "           'colsample_bytree' : 0.3,  'subsample_freq' : 1,  'subsample' : 0.6,\n",
    "           'learning_rate': 0.01,  'num_leaves': 3, \n",
    "         }\n",
    "y_train = Y['2']\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=42)\n",
    "a2 = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold_n, (trn_idx, val_idx) in enumerate(folds.split(X_train_, y_train)):\n",
    "    print('Fold', fold_n + 1)\n",
    "    X_trn, X_val = X_train[trn_idx], X_train[val_idx]\n",
    "    y_trn, y_val = y_train[trn_idx], y_train[val_idx]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_trn, label=y_trn)\n",
    "    valid_data = lgb.Dataset(X_val, label=y_val)\n",
    "        \n",
    "    clf = lgb.train(params, train_data, num_boost_round=10000, valid_sets = [train_data, valid_data], \n",
    "                    verbose_eval=500, early_stopping_rounds = 100) #categorical_feature = cat_features, \n",
    "    \n",
    "    a2 += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "0:\tlearn: 0.5274521\ttest: 0.5035906\tbest: 0.5035906 (0)\ttotal: 28.9ms\tremaining: 2m 53s\n",
      "bestTest = 0.5785573721\n",
      "bestIteration = 113\n",
      "Shrink model to first 114 iterations.\n",
      "fold n°2\n",
      "0:\tlearn: 0.5269319\ttest: 0.5108259\tbest: 0.5108259 (0)\ttotal: 26.3ms\tremaining: 2m 37s\n",
      "bestTest = 0.5939709842\n",
      "bestIteration = 141\n",
      "Shrink model to first 142 iterations.\n",
      "fold n°3\n",
      "0:\tlearn: 0.5181474\ttest: 0.5254061\tbest: 0.5254061 (0)\ttotal: 27.5ms\tremaining: 2m 45s\n",
      "bestTest = 0.6072658002\n",
      "bestIteration = 392\n",
      "Shrink model to first 393 iterations.\n",
      "fold n°4\n",
      "0:\tlearn: 0.5091484\ttest: 0.4987612\tbest: 0.4987612 (0)\ttotal: 26.3ms\tremaining: 2m 37s\n",
      "bestTest = 0.608835578\n",
      "bestIteration = 168\n",
      "Shrink model to first 169 iterations.\n",
      "fold n°5\n",
      "0:\tlearn: 0.5215309\ttest: 0.5244653\tbest: 0.5244653 (0)\ttotal: 28.2ms\tremaining: 2m 49s\n",
      "bestTest = 0.6130445302\n",
      "bestIteration = 13\n",
      "Shrink model to first 14 iterations.\n",
      "CPU times: user 1min 16s, sys: 18.6 s, total: 1min 34s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#catboost\n",
    "params = {'loss_function' : 'Logloss', 'eval_metric' : 'AUC', 'logging_level' : 'Silent', 'task_type' : 'GPU',\n",
    "          'leaf_estimation_iterations': 1, 'boosting_type':'Ordered',  \n",
    "          'iterations': 400,  'depth':2,  'learning_rate': 0.02, 'l2_leaf_reg': 5.5,\n",
    "         }\n",
    "\n",
    "y_train = Y['2']\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=42)\n",
    "b2 = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    trn_data = Pool(X_train[trn_idx], label=y_train[trn_idx])#, cat_features=cat_feat\n",
    "    val_data = Pool(X_train[val_idx], label=y_train[val_idx])#, cat_features=cat_feat\n",
    "\n",
    "    clf = catboost.train(params=params, pool = trn_data, eval_set=val_data, num_boost_round=6000, \n",
    "                         early_stopping_rounds=100, verbose_eval=1000) \n",
    "\n",
    "    #Прогноз\n",
    "    b2 += clf.predict(X_test, prediction_type='Probability')[:, 1] / folds.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предсказание для у3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Fold  1 roc_auc : 0.597058\n",
      "fold n°2\n",
      "Fold  2 roc_auc : 0.608889\n",
      "fold n°3\n",
      "Fold  3 roc_auc : 0.649703\n",
      "fold n°4\n",
      "Fold  4 roc_auc : 0.612179\n",
      "fold n°5\n",
      "Fold  5 roc_auc : 0.608556\n",
      "Out of folds AUC = 0.6148429534774495\n"
     ]
    }
   ],
   "source": [
    "#logit\n",
    "y_train = Y['3']\n",
    "svd = TruncatedSVD(n_components=200, algorithm='randomized', random_state=42)\n",
    "svd.fit(X_train)\n",
    "X_svd_train = svd.transform(X_train)\n",
    "X_svd_test = svd.transform(X_test)\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=22)\n",
    "y_3 = np.zeros(X_svd_test.shape[0])\n",
    "oof = np.zeros(X_svd_train.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_svd_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    X_trn = X_svd_train[trn_idx]\n",
    "    y_trn = y_train[trn_idx]\n",
    "    X_val = X_svd_train[val_idx]\n",
    "    y_val = y_train[val_idx]\n",
    "\n",
    "    clf = logit.fit(X_trn, y_trn)\n",
    "    oof[val_idx] = clf.predict_proba(X_val)[:, 1]\n",
    "    print('Fold %2d roc_auc : %.6f' % (fold_ + 1, roc_auc_score(y_val, oof[val_idx]))) \n",
    "    \n",
    "    y_3 += clf.predict_proba(X_svd_test) [:, 1] / folds.n_splits\n",
    "    \n",
    "print(f\"Out of folds AUC = {roc_auc_score(y_train, oof)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's auc: 0.643919\tvalid_1's auc: 0.598896\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[153]\ttraining's auc: 0.668561\tvalid_1's auc: 0.637876\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's auc: 0.660949\tvalid_1's auc: 0.665249\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's auc: 0.637407\tvalid_1's auc: 0.60238\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's auc: 0.630428\tvalid_1's auc: 0.611195\n"
     ]
    }
   ],
   "source": [
    "#lgb\n",
    "params = {'objective' : 'binary', 'metric' : 'auc', 'boosting_type' : 'gbdt', \n",
    "           'colsample_bytree' : 0.5,  'subsample_freq' : 1,  'subsample' : 0.6,\n",
    "          'learning_rate': 0.005,  'num_leaves': 3, \n",
    "         }\n",
    "y_train = Y['3']\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=42)\n",
    "a3 = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold_n, (trn_idx, val_idx) in enumerate(folds.split(X_train_, y_train)):\n",
    "    print('Fold', fold_n + 1)\n",
    "    X_trn, X_val = X_train[trn_idx], X_train[val_idx]\n",
    "    y_trn, y_val = y_train[trn_idx], y_train[val_idx]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_trn, label=y_trn)\n",
    "    valid_data = lgb.Dataset(X_val, label=y_val)\n",
    "        \n",
    "    clf = lgb.train(params, train_data, num_boost_round=10000, valid_sets = [train_data, valid_data], \n",
    "                    verbose_eval=500, early_stopping_rounds = 100) #categorical_feature = cat_features, \n",
    "    \n",
    "    a3 += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "0:\tlearn: 0.6071786\ttest: 0.5811117\tbest: 0.5811117 (0)\ttotal: 19.1ms\tremaining: 1m 54s\n",
      "bestTest = 0.6045835614\n",
      "bestIteration = 327\n",
      "Shrink model to first 328 iterations.\n",
      "fold n°2\n",
      "0:\tlearn: 0.5061838\ttest: 0.5082209\tbest: 0.5082209 (0)\ttotal: 19.4ms\tremaining: 1m 56s\n",
      "bestTest = 0.6266306788\n",
      "bestIteration = 59\n",
      "Shrink model to first 60 iterations.\n",
      "fold n°3\n",
      "0:\tlearn: 0.5035638\ttest: 0.5010340\tbest: 0.5010340 (0)\ttotal: 18.8ms\tremaining: 1m 52s\n",
      "bestTest = 0.627628088\n",
      "bestIteration = 136\n",
      "Shrink model to first 137 iterations.\n",
      "fold n°4\n",
      "0:\tlearn: 0.5073498\ttest: 0.5039259\tbest: 0.5039259 (0)\ttotal: 18.9ms\tremaining: 1m 53s\n",
      "bestTest = 0.6054557562\n",
      "bestIteration = 60\n",
      "Shrink model to first 61 iterations.\n",
      "fold n°5\n",
      "0:\tlearn: 0.5069071\ttest: 0.5051700\tbest: 0.5051700 (0)\ttotal: 18.6ms\tremaining: 1m 51s\n",
      "bestTest = 0.6336921453\n",
      "bestIteration = 167\n",
      "Shrink model to first 168 iterations.\n",
      "CPU times: user 1min 7s, sys: 15.2 s, total: 1min 22s\n",
      "Wall time: 58.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#catboost\n",
    "params = {'loss_function' : 'Logloss', 'eval_metric' : 'AUC', 'logging_level' : 'Silent', 'task_type' : 'GPU',\n",
    "          'leaf_estimation_iterations': 2, 'boosting_type':'Ordered',\n",
    "          'iterations': 400,  'depth':1,  'learning_rate': 0.02, \n",
    "         }\n",
    "\n",
    "y_train = Y['3']\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=42)\n",
    "b3 = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    trn_data = Pool(X_train[trn_idx], label=y_train[trn_idx])#, cat_features=cat_feat\n",
    "    val_data = Pool(X_train[val_idx], label=y_train[val_idx])#, cat_features=cat_feat\n",
    "\n",
    "    clf = catboost.train(params=params, pool = trn_data, eval_set=val_data, num_boost_round=6000, \n",
    "                         early_stopping_rounds=100, verbose_eval=1000) \n",
    "\n",
    "    #Прогноз\n",
    "    b3 += clf.predict(X_test, prediction_type='Probability')[:, 1] / folds.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предсказание для у4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Fold  1 roc_auc : 0.615891\n",
      "fold n°2\n",
      "Fold  2 roc_auc : 0.610505\n",
      "fold n°3\n",
      "Fold  3 roc_auc : 0.579463\n",
      "fold n°4\n",
      "Fold  4 roc_auc : 0.631003\n",
      "fold n°5\n",
      "Fold  5 roc_auc : 0.633643\n",
      "Out of folds AUC = 0.6138930768424532\n"
     ]
    }
   ],
   "source": [
    "#logit\n",
    "y_train = Y['4']\n",
    "svd = TruncatedSVD(n_components=200, algorithm='randomized', random_state=42)\n",
    "svd.fit(X_train)\n",
    "X_svd_train = svd.transform(X_train)\n",
    "X_svd_test = svd.transform(X_test)\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=22)\n",
    "y_4 = np.zeros(X_svd_test.shape[0])\n",
    "oof = np.zeros(X_svd_train.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_svd_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    X_trn = X_svd_train[trn_idx]\n",
    "    y_trn = y_train[trn_idx]\n",
    "    X_val = X_svd_train[val_idx]\n",
    "    y_val = y_train[val_idx]\n",
    "\n",
    "    clf = logit.fit(X_trn, y_trn)\n",
    "    oof[val_idx] = clf.predict_proba(X_val)[:, 1]\n",
    "    print('Fold %2d roc_auc : %.6f' % (fold_ + 1, roc_auc_score(y_val, oof[val_idx]))) \n",
    "    \n",
    "    y_4 += clf.predict_proba(X_svd_test) [:, 1] / folds.n_splits\n",
    "    \n",
    "print(f\"Out of folds AUC = {roc_auc_score(y_train, oof)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.639623\tvalid_1's auc: 0.609542\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[203]\ttraining's auc: 0.680526\tvalid_1's auc: 0.58404\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[122]\ttraining's auc: 0.661725\tvalid_1's auc: 0.601385\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's auc: 0.641033\tvalid_1's auc: 0.625136\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's auc: 0.632939\tvalid_1's auc: 0.624458\n"
     ]
    }
   ],
   "source": [
    "#lgb\n",
    "params = {'objective' : 'binary', 'metric' : 'auc', 'boosting_type' : 'gbdt', \n",
    "           'colsample_bytree' : 0.5,  'subsample_freq' : 1,  'subsample' : 0.6,\n",
    "           'learning_rate': 0.005,  'num_leaves': 3, \n",
    "         }\n",
    "y_train = Y['4']\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=42)\n",
    "a4 = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold_n, (trn_idx, val_idx) in enumerate(folds.split(X_train_, y_train)):\n",
    "    print('Fold', fold_n + 1)\n",
    "    X_trn, X_val = X_train[trn_idx], X_train[val_idx]\n",
    "    y_trn, y_val = y_train[trn_idx], y_train[val_idx]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_trn, label=y_trn)\n",
    "    valid_data = lgb.Dataset(X_val, label=y_val)\n",
    "        \n",
    "    clf = lgb.train(params, train_data, num_boost_round=10000, valid_sets = [train_data, valid_data], \n",
    "                    verbose_eval=500, early_stopping_rounds = 100) #categorical_feature = cat_features, \n",
    "    \n",
    "    a4 += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "0:\tlearn: 0.5081928\ttest: 0.5065751\tbest: 0.5065751 (0)\ttotal: 27ms\tremaining: 2m 41s\n",
      "bestTest = 0.6127967238\n",
      "bestIteration = 174\n",
      "Shrink model to first 175 iterations.\n",
      "fold n°2\n",
      "0:\tlearn: 0.5868837\ttest: 0.5756368\tbest: 0.5756368 (0)\ttotal: 23.5ms\tremaining: 2m 20s\n",
      "bestTest = 0.6110355258\n",
      "bestIteration = 94\n",
      "Shrink model to first 95 iterations.\n",
      "fold n°3\n",
      "0:\tlearn: 0.5065753\ttest: 0.5002002\tbest: 0.5002002 (0)\ttotal: 28ms\tremaining: 2m 48s\n",
      "bestTest = 0.6446183026\n",
      "bestIteration = 163\n",
      "Shrink model to first 164 iterations.\n",
      "fold n°4\n",
      "0:\tlearn: 0.5095312\ttest: 0.5071666\tbest: 0.5071666 (0)\ttotal: 26.2ms\tremaining: 2m 37s\n",
      "bestTest = 0.5655074567\n",
      "bestIteration = 34\n",
      "Shrink model to first 35 iterations.\n",
      "fold n°5\n",
      "0:\tlearn: 0.5063785\ttest: 0.4936390\tbest: 0.4936390 (0)\ttotal: 24.1ms\tremaining: 2m 24s\n",
      "bestTest = 0.5965273678\n",
      "bestIteration = 80\n",
      "Shrink model to first 81 iterations.\n",
      "CPU times: user 1min 8s, sys: 16.1 s, total: 1min 24s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#catboost\n",
    "params = {'loss_function' : 'Logloss', 'eval_metric' : 'AUC', 'logging_level' : 'Silent', 'task_type' : 'GPU',\n",
    "          'leaf_estimation_iterations': 2, 'boosting_type':'Ordered',  \n",
    "          'iterations': 400,  'depth':2,  'learning_rate': 0.02, \n",
    "         }\n",
    "\n",
    "y_train = Y['4']\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=42)\n",
    "b4 = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    trn_data = Pool(X_train[trn_idx], label=y_train[trn_idx])#, cat_features=cat_feat\n",
    "    val_data = Pool(X_train[val_idx], label=y_train[val_idx])#, cat_features=cat_feat\n",
    "\n",
    "    clf = catboost.train(params=params, pool = trn_data, eval_set=val_data, num_boost_round=6000, \n",
    "                         early_stopping_rounds=100, verbose_eval=1000) \n",
    "\n",
    "    #Прогноз\n",
    "    b4 += clf.predict(X_test, prediction_type='Probability')[:, 1] / folds.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предсказание для у5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Fold  1 roc_auc : 0.603807\n",
      "fold n°2\n",
      "Fold  2 roc_auc : 0.623345\n",
      "fold n°3\n",
      "Fold  3 roc_auc : 0.601511\n",
      "fold n°4\n",
      "Fold  4 roc_auc : 0.626674\n",
      "fold n°5\n",
      "Fold  5 roc_auc : 0.627683\n",
      "Out of folds AUC = 0.6151044034174086\n"
     ]
    }
   ],
   "source": [
    "#logit\n",
    "y_train = Y['5']\n",
    "svd = TruncatedSVD(n_components=200, algorithm='randomized', random_state=42)\n",
    "svd.fit(X_train)\n",
    "X_svd_train = svd.transform(X_train)\n",
    "X_svd_test = svd.transform(X_test)\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=22)\n",
    "y_5 = np.zeros(X_svd_test.shape[0])\n",
    "oof = np.zeros(X_svd_train.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_svd_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    X_trn = X_svd_train[trn_idx]\n",
    "    y_trn = y_train[trn_idx]\n",
    "    X_val = X_svd_train[val_idx]\n",
    "    y_val = y_train[val_idx]\n",
    "\n",
    "    clf = logit.fit(X_trn, y_trn)\n",
    "    oof[val_idx] = clf.predict_proba(X_val)[:, 1]\n",
    "    print('Fold %2d roc_auc : %.6f' % (fold_ + 1, roc_auc_score(y_val, oof[val_idx]))) \n",
    "    \n",
    "    y_5 += clf.predict_proba(X_svd_test) [:, 1] / folds.n_splits\n",
    "    \n",
    "print(f\"Out of folds AUC = {roc_auc_score(y_train, oof)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's auc: 0.709824\tvalid_1's auc: 0.57637\n",
      "Early stopping, best iteration is:\n",
      "[558]\ttraining's auc: 0.71475\tvalid_1's auc: 0.578007\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's auc: 0.667469\tvalid_1's auc: 0.60082\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's auc: 0.660459\tvalid_1's auc: 0.561186\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's auc: 0.648601\tvalid_1's auc: 0.608009\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.645858\tvalid_1's auc: 0.603124\n"
     ]
    }
   ],
   "source": [
    "#lgb\n",
    "params = {'objective' : 'binary', 'metric' : 'auc', 'boosting_type' : 'gbdt', \n",
    "           'colsample_bytree' : 0.3,  'subsample_freq' : 1,  'subsample' : 0.6,\n",
    "          'learning_rate': 0.005,  'num_leaves': 3, \n",
    "         }\n",
    "y_train = Y['5']\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=42)\n",
    "a5 = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold_n, (trn_idx, val_idx) in enumerate(folds.split(X_train_, y_train)):\n",
    "    print('Fold', fold_n + 1)\n",
    "    X_trn, X_val = X_train[trn_idx], X_train[val_idx]\n",
    "    y_trn, y_val = y_train[trn_idx], y_train[val_idx]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_trn, label=y_trn)\n",
    "    valid_data = lgb.Dataset(X_val, label=y_val)\n",
    "        \n",
    "    clf = lgb.train(params, train_data, num_boost_round=10000, valid_sets = [train_data, valid_data], \n",
    "                    verbose_eval=500, early_stopping_rounds = 100) #categorical_feature = cat_features, \n",
    "    \n",
    "    a5 += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "0:\tlearn: 0.5071253\ttest: 0.4934080\tbest: 0.4934080 (0)\ttotal: 31.2ms\tremaining: 3m 7s\n",
      "bestTest = 0.6124601364\n",
      "bestIteration = 229\n",
      "Shrink model to first 230 iterations.\n",
      "fold n°2\n",
      "0:\tlearn: 0.5053622\ttest: 0.5005680\tbest: 0.5005680 (0)\ttotal: 27.9ms\tremaining: 2m 47s\n",
      "bestTest = 0.5744367242\n",
      "bestIteration = 381\n",
      "Shrink model to first 382 iterations.\n",
      "fold n°3\n",
      "0:\tlearn: 0.5077508\ttest: 0.5076533\tbest: 0.5076533 (0)\ttotal: 24.9ms\tremaining: 2m 29s\n",
      "bestTest = 0.620056659\n",
      "bestIteration = 114\n",
      "Shrink model to first 115 iterations.\n",
      "fold n°4\n",
      "0:\tlearn: 0.5031999\ttest: 0.5009645\tbest: 0.5009645 (0)\ttotal: 23.8ms\tremaining: 2m 22s\n",
      "bestTest = 0.6074842811\n",
      "bestIteration = 32\n",
      "Shrink model to first 33 iterations.\n",
      "fold n°5\n",
      "0:\tlearn: 0.5047716\ttest: 0.4988334\tbest: 0.4988334 (0)\ttotal: 26.4ms\tremaining: 2m 38s\n",
      "bestTest = 0.5616071522\n",
      "bestIteration = 102\n",
      "Shrink model to first 103 iterations.\n",
      "CPU times: user 1min 16s, sys: 17.5 s, total: 1min 34s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#catboost\n",
    "params = {'loss_function' : 'Logloss', 'eval_metric' : 'AUC', 'logging_level' : 'Silent', 'task_type' : 'GPU',\n",
    "          'leaf_estimation_iterations': 2, 'boosting_type':'Ordered',  \n",
    "          'iterations': 400,  'depth':2,  'learning_rate': 0.02, \n",
    "         }\n",
    "\n",
    "y_train = Y['5']\n",
    "\n",
    "num_folds = 5\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=42)\n",
    "b5 = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    trn_data = Pool(X_train[trn_idx], label=y_train[trn_idx])#, cat_features=cat_feat\n",
    "    val_data = Pool(X_train[val_idx], label=y_train[val_idx])#, cat_features=cat_feat\n",
    "\n",
    "    clf = catboost.train(params=params, pool = trn_data, eval_set=val_data, num_boost_round=6000, \n",
    "                         early_stopping_rounds=100, verbose_eval=1000) \n",
    "\n",
    "    #Прогноз\n",
    "    b5 += clf.predict(X_test, prediction_type='Probability')[:, 1] / folds.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Финальное решение "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результатом модели является submission1. Не оставалось попыток, чтобы проверить, сколько наберет это решение. Поэтому, чтобы максимизировать пользу от последней попытки, этот сабмит было решено объединить с предыдущим лучшим решением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.320297</td>\n",
       "      <td>0.342647</td>\n",
       "      <td>0.270872</td>\n",
       "      <td>0.304255</td>\n",
       "      <td>0.374553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.338998</td>\n",
       "      <td>0.294868</td>\n",
       "      <td>0.289930</td>\n",
       "      <td>0.293493</td>\n",
       "      <td>0.422721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.358539</td>\n",
       "      <td>0.401801</td>\n",
       "      <td>0.263127</td>\n",
       "      <td>0.312543</td>\n",
       "      <td>0.372728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.273669</td>\n",
       "      <td>0.308732</td>\n",
       "      <td>0.296852</td>\n",
       "      <td>0.285238</td>\n",
       "      <td>0.431408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.344934</td>\n",
       "      <td>0.328316</td>\n",
       "      <td>0.386120</td>\n",
       "      <td>0.364364</td>\n",
       "      <td>0.392184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1         2         3         4         5\n",
       "id                                                  \n",
       "0   0.320297  0.342647  0.270872  0.304255  0.374553\n",
       "1   0.338998  0.294868  0.289930  0.293493  0.422721\n",
       "2   0.358539  0.401801  0.263127  0.312543  0.372728\n",
       "4   0.273669  0.308732  0.296852  0.285238  0.431408\n",
       "7   0.344934  0.328316  0.386120  0.364364  0.392184"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission1 = pd.DataFrame(index = X1_test.index)\n",
    "submission1['1'] = np.exp(0.34*np.log(a1) + 0.32*np.log(y_1)+ 0.33*np.log(b1))\n",
    "submission1['2'] = np.exp(0.34*np.log(a2) + 0.33*np.log(y_2)+ 0.33*np.log(b2))\n",
    "submission1['3'] = np.exp(0.34*np.log(a3) + 0.33*np.log(y_3)+ 0.33*np.log(b3))\n",
    "submission1['4'] = np.exp(0.34*np.log(a4) + 0.33*np.log(y_4)+ 0.33*np.log(b4))\n",
    "submission1['5'] = np.exp(0.34*np.log(a5) + 0.33*np.log(y_5)+ 0.33*np.log(b5))\n",
    "submission1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission1[['1', '2', '3', '4', '5']].to_csv('subm_34.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время работы менее 10 минут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
